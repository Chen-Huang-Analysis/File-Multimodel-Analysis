{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# This notebook only extract graph, text, layout from PDF files",
   "id": "8ddc8a2aeb5fefc5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Read PDF Data",
   "id": "e5a0b839c1ca0f88"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "PDF_File_Path=r\"Data\\PDF\"\n",
    "PDF_File_Path=os.path.join(os.path.dirname(os.getcwd()),PDF_File_Path)\n",
    "\n",
    "PDF_Extract_Output_Path=r\"Data/Extract_Output/text\"\n",
    "PDF_Extract_Output_Path=os.path.join(os.path.dirname(os.getcwd()),PDF_Extract_Output_Path)\n",
    "#in case of no such folder\n",
    "os.makedirs(PDF_Extract_Output_Path, exist_ok=True)\n",
    "\n",
    "print(\"PDF file path: {}\\nPDF Extract Output Path: {}\".format(PDF_File_Path, PDF_Extract_Output_Path) )"
   ],
   "id": "f9b486f0f91826ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Text Extraction",
   "id": "5f91b4298837a4fa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### The sample of text extraction (only 1 pdf)",
   "id": "1c60474c584d1189"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import base64\n",
    "\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, Qwen2VLForConditionalGeneration\n",
    "\n",
    "from olmocr.data.renderpdf import render_pdf_to_base64png\n",
    "from olmocr.prompts import build_finetuning_prompt\n",
    "from olmocr.prompts.anchor import get_anchor_text\n",
    "\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\"allenai/olmOCR-7B-0225-preview\", torch_dtype=torch.bfloat16).eval()\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-7B-Instruct\",use_fast=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def extract_text_per_page(pdf_path:str,page_num:int,model_current=model,processor_current=processor):\n",
    "    image_base64 = render_pdf_to_base64png(pdf_path, page_num, target_longest_image_dim=1024)\n",
    "\n",
    "    # Build the prompt, using document metadata\n",
    "    # anchor_text = get_anchor_text(pdf_path, page_num, pdf_engine=\"pdfreport\", target_length=4000)\n",
    "    # prompt = build_finetuning_prompt(anchor_text)\n",
    "\n",
    "    #print(prompt)\n",
    "    # Build the full prompt\n",
    "    messages = [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": \"Below is the image of one page of a document, as well as some raw textual content that was previously extracted for it. Just return the plain text representation of this document as if you were reading it naturally. Do not hallucinate.\"},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64}\"}},\n",
    "                    ],\n",
    "                }\n",
    "            ]\n",
    "\n",
    "    # Apply the chat template and processor\n",
    "    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    main_image = Image.open(BytesIO(base64.b64decode(image_base64)))\n",
    "\n",
    "    inputs = processor_current(\n",
    "        text=[text],\n",
    "        images=[main_image],\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs = {key: value.to(device) for (key, value) in inputs.items()}\n",
    "\n",
    "\n",
    "    # Generate the output\n",
    "    output = model_current.generate(\n",
    "                **inputs,\n",
    "                temperature=0.8,\n",
    "                max_new_tokens=10000,\n",
    "                num_return_sequences=1,\n",
    "                do_sample=True,\n",
    "            )\n",
    "\n",
    "    # Decode the output\n",
    "    prompt_length = inputs[\"input_ids\"].shape[1]\n",
    "    new_tokens = output[:, prompt_length:]\n",
    "    text_output = processor_current.tokenizer.batch_decode(\n",
    "        new_tokens,\n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "    return text_output\n",
    "# ['{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Molmo and PixMo:\\\\nOpen Weights and Open Data\\\\nfor State-of-the']\n"
   ],
   "id": "f01b72a07886da77",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Extract the natural text from 1 page pdf",
   "id": "a757635dbad2b975"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "# text_output=extract_text_per_page(\"C:/Users/Tommy/Downloads/ESGreporttemplate/A/2023-CSR-report_e.pdf\",5)\n",
    "# output_data = json.loads(text_output[0])\n",
    "# print(output_data['natural_text'])\n",
    "# !python -m olmocr.pipeline ./localworkspace --markdown --pdfs D:\\pycharmProjects\\File-Multimodel-Analysis\\Data\\PDF\\2023-CSR-report_e.pdf\n"
   ],
   "id": "fefd227581ca4dc1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Extract all text from all pdfs",
   "id": "4b0bdd107f86c0f8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import fitz\n",
    "\n",
    "def list_pdfs_in_folder(path):\n",
    "    if not os.path.isdir(path):\n",
    "        raise ValueError(f\"this path is not a folder: {path}\")\n",
    "\n",
    "    pdf_paths = {}\n",
    "    for name in os.listdir(path):\n",
    "        full = os.path.join(path, name)\n",
    "\n",
    "        if not os.path.isfile(full):\n",
    "            raise ValueError(f\"this is not a file: {full}\")\n",
    "\n",
    "        if not name.lower().endswith('.pdf'):\n",
    "            raise ValueError(f\"some file is not pdf: {full}\")\n",
    "        pdf_paths[name] = full\n",
    "\n",
    "    return pdf_paths\n",
    "\n",
    "def save_dict_to_json(data: dict, filepath: str, *, indent: int = 4, ensure_ascii: bool = False) -> None:\n",
    "    with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=indent, ensure_ascii=ensure_ascii)\n",
    "\n",
    "def extract_text_all_pdf():\n",
    "    pdf_paths = list_pdfs_in_folder(PDF_File_Path)\n",
    "    for pdf_name,pdf_path in pdf_paths.items():\n",
    "        text_output_each_pdf={}\n",
    "        #remove .pdf, only file name\n",
    "        name = os.path.splitext(pdf_name)[0]\n",
    "        text_output_each_pdf[\"filename\"]=name\n",
    "        text_output_each_pdf[\"filepath\"]=pdf_path\n",
    "        doc = fitz.open(pdf_path)\n",
    "        for page_index, page in enumerate(doc, start=1):\n",
    "            text_output_each_page=extract_text_per_page(pdf_path,page_index,model_current=model,processor_current=processor)\n",
    "            text_output_each_pdf[\"{}\".format(page_index)] = text_output_each_page\n",
    "        save_dict_to_json(text_output_each_pdf, os.path.join(PDF_Extract_Output_Path, \"{}.json\".format(name)))\n",
    "        print(\"File has been extracted successfully: {}\\n\".format(pdf_name))"
   ],
   "id": "2cdf63328ebe6746",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "extract_text_all_pdf()\n",
    "# print(list_pdfs_in_folder(parent))"
   ],
   "id": "247e44267492f1d6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Extract Layout",
   "id": "e003c641a43e9789"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "40b1032ac061957c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
