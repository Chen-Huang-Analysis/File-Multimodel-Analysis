{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# This notebook only extract graph, text, layout from PDF files",
   "id": "8ddc8a2aeb5fefc5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T17:18:58.525372Z",
     "start_time": "2025-06-21T17:18:58.522101Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# !pip install PyMuPDF\n",
    "# !pip install doclayout-yolo==0.0.4\n",
    "# !pip install olmocr"
   ],
   "id": "a0a2b62795289871",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Read PDF Data",
   "id": "e5a0b839c1ca0f88"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T17:18:58.626455Z",
     "start_time": "2025-06-21T17:18:58.622907Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# from paddle.static.amp.fp16_lists import white_list\n",
    "\n",
    "PDF_File_Path=r\"Data\\PDF\"\n",
    "PDF_File_Path=os.path.join(os.path.dirname(os.getcwd()),PDF_File_Path)\n",
    "\n",
    "PDF_Text_Extract_Output_Path= r\"Data/Extract_Output/text\"\n",
    "PDF_Text_Extract_Output_Path=os.path.join(os.path.dirname(os.getcwd()), PDF_Text_Extract_Output_Path)\n",
    "#in case of no such folder\n",
    "os.makedirs(PDF_Text_Extract_Output_Path, exist_ok=True)\n",
    "\n",
    "PDF_Layout_Extract_Output_Path= r\"Data/Extract_Output/layout\"\n",
    "PDF_Layout_Extract_Output_Path=os.path.join(os.path.dirname(os.getcwd()), PDF_Layout_Extract_Output_Path)\n",
    "#in case of no such folder\n",
    "os.makedirs(PDF_Layout_Extract_Output_Path, exist_ok=True)\n",
    "\n",
    "print(\"PDF file path: {}\\nPDF Extract Output Path: {}\".format(PDF_File_Path, PDF_Text_Extract_Output_Path))"
   ],
   "id": "f9b486f0f91826ac",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF file path: D:\\pycharmProjects\\File-Multimodel-Analysis\\Data\\PDF\n",
      "PDF Extract Output Path: D:\\pycharmProjects\\File-Multimodel-Analysis\\Data/Extract_Output/text\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Text Extraction",
   "id": "5f91b4298837a4fa"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### The sample of text extraction (only 1 pdf)",
   "id": "1c60474c584d1189"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T17:19:08.107663Z",
     "start_time": "2025-06-21T17:18:58.636837Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import base64\n",
    "\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, Qwen2VLForConditionalGeneration\n",
    "\n",
    "from olmocr.data.renderpdf import render_pdf_to_base64png\n",
    "from olmocr.prompts import build_finetuning_prompt\n",
    "from olmocr.prompts.anchor import get_anchor_text\n",
    "\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\"allenai/olmOCR-7B-0225-preview\", torch_dtype=torch.bfloat16).eval()\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-7B-Instruct\",use_fast=True)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def extract_text_per_page(pdf_path:str,page_num:int,model_current=model,processor_current=processor):\n",
    "    image_base64 = render_pdf_to_base64png(pdf_path, page_num, target_longest_image_dim=1024)\n",
    "\n",
    "    # Build the prompt, using document metadata\n",
    "    # anchor_text = get_anchor_text(pdf_path, page_num, pdf_engine=\"pdfreport\", target_length=4000)\n",
    "    # prompt = build_finetuning_prompt(anchor_text)\n",
    "\n",
    "    #print(prompt)\n",
    "    # Build the full prompt\n",
    "    messages = [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\"type\": \"text\", \"text\": \"Below is the image of one page of a document, as well as some raw textual content that was previously extracted for it. Just return the plain text representation of this document as if you were reading it naturally. Do not hallucinate.\"},\n",
    "                        {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64}\"}},\n",
    "                    ],\n",
    "                }\n",
    "            ]\n",
    "\n",
    "    # Apply the chat template and processor\n",
    "    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    main_image = Image.open(BytesIO(base64.b64decode(image_base64)))\n",
    "\n",
    "    inputs = processor_current(\n",
    "        text=[text],\n",
    "        images=[main_image],\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs = {key: value.to(device) for (key, value) in inputs.items()}\n",
    "\n",
    "\n",
    "    # Generate the output\n",
    "    output = model_current.generate(\n",
    "                **inputs,\n",
    "                temperature=0.8,\n",
    "                max_new_tokens=8000,\n",
    "                num_return_sequences=1,\n",
    "                do_sample=True,\n",
    "            )\n",
    "\n",
    "    # Decode the output\n",
    "    prompt_length = inputs[\"input_ids\"].shape[1]\n",
    "    new_tokens = output[:, prompt_length:]\n",
    "    text_output = processor_current.tokenizer.batch_decode(\n",
    "        new_tokens,\n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "    return text_output\n",
    "# ['{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Molmo and PixMo:\\\\nOpen Weights and Open Data\\\\nfor State-of-the']\n"
   ],
   "id": "f01b72a07886da77",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tommy\\anaconda3\\envs\\Multi_model-Analysis\\Lib\\site-packages\\requests\\__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "C:\\Users\\Tommy\\anaconda3\\envs\\Multi_model-Analysis\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 57.77it/s]\n",
      "You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Extract the natural text from 1 page pdf",
   "id": "a757635dbad2b975"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T17:19:08.434502Z",
     "start_time": "2025-06-21T17:19:08.431564Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import json\n",
    "# text_output=extract_text_per_page(\"C:/Users/Tommy/Downloads/ESGreporttemplate/A/2023-CSR-report_e.pdf\",5)\n",
    "# output_data = json.loads(text_output[0])\n",
    "# print(output_data['natural_text'])\n",
    "# !python -m olmocr.pipeline ./localworkspace --markdown --pdfs D:\\pycharmProjects\\File-Multimodel-Analysis\\Data\\PDF\\2023-CSR-report_e.pdf\n"
   ],
   "id": "fefd227581ca4dc1",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Extract all text from all pdfs",
   "id": "4b0bdd107f86c0f8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-21T17:19:08.761005Z",
     "start_time": "2025-06-21T17:19:08.711843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import fitz\n",
    "from Tools.Basic_Functions import *\n",
    "def extract_text_all_pdf():\n",
    "    pdf_paths = list_pdfs_in_folder(PDF_File_Path)\n",
    "    for pdf_name,pdf_path in pdf_paths.items():\n",
    "        text_output_each_pdf={}\n",
    "        #remove .pdf, only file name\n",
    "        name = os.path.splitext(pdf_name)[0]\n",
    "        text_output_each_pdf[\"filefullname\"]=pdf_name\n",
    "        text_output_each_pdf[\"filename\"]=name\n",
    "        text_output_each_pdf[\"filepath\"]=pdf_path\n",
    "        content_output_each_pdf={}\n",
    "        doc = fitz.open(pdf_path)\n",
    "        # get text from each page of pdf\n",
    "        for page_index, page in enumerate(doc, start=1):\n",
    "            text_output_each_page=extract_text_per_page(pdf_path,page_index,model_current=model,processor_current=processor)\n",
    "            content_output_each_pdf[\"{}\".format(page_index)] = text_output_each_page\n",
    "            print(f\"{pdf_name} page {page_index} has been extracted.\")\n",
    "        text_output_each_pdf[\"content\"]=content_output_each_pdf\n",
    "        #save the text\n",
    "        save_dict_to_json(text_output_each_pdf, os.path.join(PDF_Text_Extract_Output_Path, \"{}.json\".format(name)))\n",
    "        print(\"File has been extracted successfully: {}\\n\".format(pdf_name))"
   ],
   "id": "2cdf63328ebe6746",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-06-21T17:19:09.030941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "extract_text_all_pdf()\n",
    "# print(list_pdfs_in_folder(parent))"
   ],
   "id": "247e44267492f1d6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-CSR-report_e.pdf page 1 has been extracted.\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Layout Extraction",
   "id": "e003c641a43e9789"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from doclayout_yolo import YOLOv10\n",
    "import numpy as np\n",
    "import cv2\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "model = YOLOv10(\"../Tools/doclayout_yolo_docstructbench_imgsz1024.pt\")\n",
    "\n",
    "class detect_object:\n",
    "    def __init__(self, clas_name, x1, y1, x2, y2, conf):\n",
    "        self.clas_name = clas_name\n",
    "        self.x1 = x1\n",
    "        self.y1 = y1\n",
    "        self.x2 = x2\n",
    "        self.y2 = y2\n",
    "        self.conf = conf\n",
    "\n",
    "    def class_to_dict(self):\n",
    "        result_dict={}\n",
    "        result_dict[\"class_name\"]=self.clas_name\n",
    "        result_dict[\"x1\"]=str(self.x1)\n",
    "        result_dict[\"y1\"]=str(self.y1)\n",
    "        result_dict[\"x2\"]=str(self.x2)\n",
    "        result_dict[\"y2\"]=str(self.y2)\n",
    "        result_dict[\"conf\"]=str(self.conf)\n",
    "        return result_dict\n",
    "\n",
    "\n",
    "def extract_layout_per_pdf(pdf_name:str,pdf_path:str):\n",
    "    name = os.path.splitext(pdf_name)[0]\n",
    "    pages = convert_from_path(pdf_path, dpi=300, fmt='png')\n",
    "    det_res = model.predict(\n",
    "    pages,   # Image to predict\n",
    "    imgsz=1024,        # Prediction image size\n",
    "    conf=0.2,          # Confidence threshold\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")    # Device to use (e.g., 'cuda:0' or 'cpu')\n",
    "    )\n",
    "    content_of_pdf={}\n",
    "    content_of_pdf[\"filename\"]=pdf_name\n",
    "    content_of_pdf[\"filepath\"]=pdf_path\n",
    "    obj_per_page={}\n",
    "    for page_index,res in enumerate(det_res, start=1):\n",
    "        obj_list=[]\n",
    "        for box in res.boxes.data.cpu().numpy():\n",
    "            x1, y1, x2, y2, conf, cls_id = box\n",
    "            cls_name = res.names[int(cls_id)]\n",
    "            det_obj = detect_object(cls_name, x1, y1, x2, y2, conf)\n",
    "            obj_list.append(det_obj.class_to_dict())\n",
    "            # print(f\"Page {page_index}: {cls_name:<15} [{int(x1)}, {int(y1)}, {int(x2)}, {int(y2)}], conf={conf:.2f}\")\n",
    "        obj_per_page[f\"{page_index}\"] = obj_list\n",
    "\n",
    "        #draw the images\n",
    "        annotated = res.plot(pil=True, line_width=3, font_size=16)\n",
    "        arr = np.array(annotated)[:, :, ::-1]  # PIL 是 RGB，OpenCV 用 BGR 顺序\n",
    "\n",
    "        #define images store path\n",
    "        image_output_path=os.path.join(PDF_Layout_Extract_Output_Path,\"images/\",f\"{name}\")\n",
    "        os.makedirs(image_output_path, exist_ok=True)\n",
    "        saveOrNot=cv2.imwrite(f\"{image_output_path}/page{page_index}.jpg\", arr, [cv2.IMWRITE_JPEG_QUALITY, 90]) #save the image\n",
    "        if not saveOrNot:\n",
    "            print(f\"{page_index} page {page_index} saved failed\")\n",
    "\n",
    "    #store the dictionary as json file\n",
    "    content_of_pdf[\"obj_detected\"] = obj_per_page\n",
    "    json_save_path=os.path.join(PDF_Layout_Extract_Output_Path,\"jsons\")\n",
    "    os.makedirs(json_save_path, exist_ok=True)\n",
    "    # print(json_save_path)\n",
    "    save_dict_to_json(content_of_pdf, os.path.join(json_save_path, \"{}.json\".format(name)))\n",
    "\n",
    "\n",
    "def extract_layout_all_pdf():\n",
    "    # white_list=[\"INNOLUX%202023%20ESG%20Report%20e-book%20EN_768472.pdf\",\"Stellantis-2023-CSR-Report.pdf\",\"Sustainability-Report-2023-Final-Version-2.pdf\"]\n",
    "    pdf_paths = list_pdfs_in_folder(PDF_File_Path)\n",
    "    for pdf_name,pdf_path in pdf_paths.items():\n",
    "        # if pdf_name in white_list:\n",
    "        extract_layout_per_pdf(pdf_name=pdf_name,pdf_path=pdf_path)"
   ],
   "id": "40b1032ac061957c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# extract_layout_per_pdf(pdf_path=\"C:/Users/Tommy/Downloads/ESGreporttemplate/A/2023-CSR-report_e.pdf\",pdf_name=\"2023-CSR-report_e.pdf\")",
   "id": "ba56e8a8ac71095a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Extract layout information(title,figure,table) from all pdf",
   "id": "3c703ef2e141639c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "#extract_layout_all_pdf()",
   "id": "3b86ab1f47bb95dd",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
