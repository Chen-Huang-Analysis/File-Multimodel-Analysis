{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### The sample of text extraction (only 1 pdf)",
   "id": "8e2a787a6fc1f909"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-06-20T15:21:13.934559Z"
    }
   },
   "source": [
    "import torch\n",
    "import base64\n",
    "import os\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, Qwen2VLForConditionalGeneration\n",
    "\n",
    "from olmocr.data.renderpdf import render_pdf_to_base64png\n",
    "from olmocr.prompts import build_finetuning_prompt\n",
    "from olmocr.prompts.anchor import get_anchor_text\n",
    "\n",
    "# Initialize the model\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\"allenai/olmOCR-7B-0225-preview\", torch_dtype=torch.bfloat16).eval()\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-7B-Instruct\",use_fast=True)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Grab a sample PDF\n",
    "# urllib.request.urlretrieve(\"https://molmo.allenai.org/paper.pdf\", \"./paper.pdf\")\n",
    "\n",
    "# Render page 1 to an image\n",
    "image_base64 = render_pdf_to_base64png(\"C:/Users/Tommy/Downloads/ESGreporttemplate/A/2023-CSR-report_e.pdf\", 5, target_longest_image_dim=1024)\n",
    "\n",
    "# Build the prompt, using document metadata\n",
    "# anchor_text = get_anchor_text(\"C:/Users/Tommy/Downloads/ESGreporttemplate/A/2023-CSR-report_e.pdf\", 5, pdf_engine=\"pdfreport\", target_length=4000)\n",
    "# prompt = build_finetuning_prompt(anchor_text)\n",
    "\n",
    "#print(prompt)\n",
    "# Build the full prompt\n",
    "messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \"Below is the image of one page of a document, as well as some raw textual content that was previously extracted for it. Just return the plain text representation of this document as if you were reading it naturally. Do not hallucinate. output **only** the natural text content.\"},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64}\"}},\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "\n",
    "# Apply the chat template and processor\n",
    "text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "main_image = Image.open(BytesIO(base64.b64decode(image_base64)))\n",
    "\n",
    "inputs = processor(\n",
    "    text=[text],\n",
    "    images=[main_image],\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "inputs = {key: value.to(device) for (key, value) in inputs.items()}\n",
    "\n",
    "\n",
    "# Generate the output\n",
    "output = model.generate(\n",
    "            **inputs,\n",
    "            temperature=0.8,\n",
    "            max_new_tokens=4000,\n",
    "            num_return_sequences=1,\n",
    "            do_sample=True,\n",
    "        )\n",
    "\n",
    "# Decode the output\n",
    "prompt_length = inputs[\"input_ids\"].shape[1]\n",
    "new_tokens = output[:, prompt_length:]\n",
    "text_output = processor.tokenizer.batch_decode(\n",
    "    new_tokens,\n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "print(text_output)\n",
    "# ['{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Molmo and PixMo:\\\\nOpen Weights and Open Data\\\\nfor State-of-the']\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tommy\\anaconda3\\envs\\MultiModel_Analysis\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 53.16it/s]\n",
      "You have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Extract the natural text from 1 page pdf",
   "id": "9afe0117b4106776"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import json\n",
    "\n",
    "output_data = json.loads(text_output[0])\n",
    "print(output_data['natural_text'])\n",
    "# !python -m olmocr.pipeline ./localworkspace --markdown --pdfs D:\\pycharmProjects\\File-Multimodel-Analysis\\Data\\PDF\\2023-CSR-report_e.pdf"
   ],
   "id": "e2f74868cdb3d262"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
