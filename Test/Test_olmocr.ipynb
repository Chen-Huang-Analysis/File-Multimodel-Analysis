{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### The sample of text extraction (only 1 pdf)",
   "id": "8e2a787a6fc1f909"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import torch\n",
    "import base64\n",
    "import os\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from transformers import AutoProcessor, Qwen2VLForConditionalGeneration\n",
    "\n",
    "from olmocr.data.renderpdf import render_pdf_to_base64png\n",
    "from olmocr.prompts import build_finetuning_prompt\n",
    "from olmocr.prompts.anchor import get_anchor_text\n",
    "\n",
    "# Initialize the model\n",
    "model = Qwen2VLForConditionalGeneration.from_pretrained(\"allenai/olmOCR-7B-0225-preview\", torch_dtype=torch.bfloat16).eval()\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2-VL-7B-Instruct\",use_fast=True)\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\\\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Grab a sample PDF\n",
    "# urllib.request.urlretrieve(\"https://molmo.allenai.org/paper.pdf\", \"./paper.pdf\")\n",
    "\n",
    "# Render page 1 to an image\n",
    "image_base64 = render_pdf_to_base64png(\"C:/Users/Tommy/Downloads/ESGreporttemplate/A/2023-CSR-report_e.pdf\", 6, target_longest_image_dim=1024)\n",
    "\n",
    "# Build the prompt, using document metadata\n",
    "# anchor_text = get_anchor_text(\"C:/Users/Tommy/Downloads/ESGreporttemplate/A/2023-CSR-report_e.pdf\", 5, pdf_engine=\"pdfreport\", target_length=4000)\n",
    "# prompt = build_finetuning_prompt(anchor_text)\n",
    "\n",
    "#print(prompt)\n",
    "# Build the full prompt\n",
    "messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": \"Below is the image of one page of a document, as well as some raw textual content that was previously extracted for it. Just return the plain text representation of this document as if you were reading it naturally. Do not hallucinate. output **only** the natural text content.\"},\n",
    "                    # {\"type\": \"text\", \"text\": prompt},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_base64}\"}},\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "\n",
    "# Apply the chat template and processor\n",
    "text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "main_image = Image.open(BytesIO(base64.b64decode(image_base64)))\n",
    "\n",
    "inputs = processor(\n",
    "    text=[text],\n",
    "    images=[main_image],\n",
    "    padding=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "inputs = {key: value.to(device) for (key, value) in inputs.items()}\n",
    "\n",
    "\n",
    "# Generate the output\n",
    "output = model.generate(\n",
    "            **inputs,\n",
    "            temperature=0.8,\n",
    "            max_new_tokens=6000,\n",
    "            num_return_sequences=1,\n",
    "            do_sample=True,\n",
    "        )\n",
    "\n",
    "# Decode the output\n",
    "prompt_length = inputs[\"input_ids\"].shape[1]\n",
    "new_tokens = output[:, prompt_length:]\n",
    "text_output = processor.tokenizer.batch_decode(\n",
    "    new_tokens,\n",
    "    skip_special_tokens=True\n",
    ")\n",
    "\n",
    "print(text_output)\n",
    "# ['{\"primary_language\":\"en\",\"is_rotation_valid\":true,\"rotation_correction\":0,\"is_table\":false,\"is_diagram\":false,\"natural_text\":\"Molmo and PixMo:\\\\nOpen Weights and Open Data\\\\nfor State-of-the']\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Extract the natural text from 1 page pdf",
   "id": "9afe0117b4106776"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "output_data = json.loads(text_output[0])\n",
    "print(output_data['natural_text'])\n",
    "# !python -m olmocr.pipeline ./localworkspace --markdown --pdfs D:\\pycharmProjects\\File-Multimodel-Analysis\\Data\\PDF\\2023-CSR-report_e.pdf"
   ],
   "id": "e2f74868cdb3d262",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
